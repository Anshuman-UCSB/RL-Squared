{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b88c10d",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "For the first stage of this project, using trained data from nexto 2v2 using our observation builders, we create a model to predict what Nexto would do given our inputs. This is essentially model distillation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a39974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "dir = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c52d0f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPKL(name):\n",
    "    with open(os.path.join(dir, name), 'rb') as f:\n",
    "        return [(x.astype('float32'), y.astype('float32'))for x,y in pickle.load(f)]\n",
    "def loadAll():\n",
    "    data = []\n",
    "    files = [x for x in os.listdir(dir) if not x.startswith('.')]\n",
    "    for f in tqdm(files):\n",
    "        data+=loadPKL(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e24b4d",
   "metadata": {},
   "source": [
    "# Pytorch section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c9f729",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9367f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import SELU\n",
    "from torch.nn import Tanh\n",
    "from torch.nn import Module\n",
    "\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975cb3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextoDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        data = loadAll()\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        for x,y in data:\n",
    "            self.X.append(x)\n",
    "            self.Y.append(y)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, i):\n",
    "        return [self.X[i], self.Y[i]]\n",
    "    def get_splits(self, n_test = .2):\n",
    "        test_size = round(n_test*len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        return random_split(self, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950d02a",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d0b058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):\n",
    "    # define model elements\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # input to first hidden layer\n",
    "        n_inputs = 119\n",
    "        \n",
    "        self.hidden1 = Linear(n_inputs, 256)\n",
    "        self.act1 = SELU()\n",
    "\n",
    "        self.hidden2 = Linear(256, 256)\n",
    "        self.act2 = SELU()\n",
    "\n",
    "        self.hidden3 = Linear(256, 128)\n",
    "        self.act3 = SELU()\n",
    "\n",
    "        self.hidden4 = Linear(128, 64)\n",
    "        self.act4 = SELU()\n",
    "        \n",
    "        # third hidden layer and output\n",
    "        self.hidden5 = Linear(64, 8)\n",
    "        self.act5 = Tanh()\n",
    "\n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        # input to first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "         # second hidden layer\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        # third hidden layer and output\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        \n",
    "        X = self.hidden4(X)\n",
    "        X = self.act4(X)\n",
    "        \n",
    "        X = self.hidden5(X)\n",
    "        X = self.act5(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dee54cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (hidden1): Linear(in_features=119, out_features=256, bias=True)\n",
       "  (act1): SELU()\n",
       "  (hidden2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (act2): SELU()\n",
       "  (hidden3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (act3): SELU()\n",
       "  (hidden4): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (act4): SELU()\n",
       "  (hidden5): Linear(in_features=64, out_features=8, bias=True)\n",
       "  (act5): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea21392",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a5f949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(batch_size):\n",
    "    # load the dataset\n",
    "    dataset = NextoDataset()\n",
    "    # calculate split\n",
    "    train, test = dataset.get_splits()\n",
    "    # prepare data loaders\n",
    "    train_dl = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29b575f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dl, valid_dl, model,epochs = 10):\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    min_valid_loss = np.inf\n",
    "    # define the optimization\n",
    "    criterion = MSELoss()\n",
    "    optimizer = Adam(model.parameters())\n",
    "    with tqdm(total=len(train_dl)) as bar:\n",
    "        for e in range(epochs):\n",
    "            train_loss = 0.0\n",
    "            model.train()     # Optional when not using Model Specific layer\n",
    "#             bar.reset()\n",
    "            for data, labels in train_dl:\n",
    "#                 bar.update(1)\n",
    "                if torch.cuda.is_available():\n",
    "                    data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                target = model(data)\n",
    "                loss = criterion(target,labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            valid_loss = 0.0\n",
    "            model.eval()     # Optional when not using Model Specific layer\n",
    "            for data, labels in valid_dl:\n",
    "                if torch.cuda.is_available():\n",
    "                    data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "                target = model(data)\n",
    "                loss = criterion(target,labels)\n",
    "                valid_loss = loss.item() * data.size(0)\n",
    "\n",
    "            print(f'Epoch {e+1} \\tTraining Loss: {train_loss / len(train_dl)} \\t Validation Loss: {valid_loss / len(valid_dl)}')\n",
    "            if min_valid_loss > valid_loss:\n",
    "                print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "                min_valid_loss = valid_loss\n",
    "                torch.save(model.state_dict(), f'models/{valid_loss/len(valid_dl)*1000:.6f}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7444e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a class prediction for one row of data\n",
    "def predict(row, model):\n",
    "    # convert row to data\n",
    "    row = Tensor([row])\n",
    "    # make prediction\n",
    "    yhat = model(row)\n",
    "    # retrieve numpy array\n",
    "    yhat = yhat.detach().numpy()\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382310db",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "334a4714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db685ddaaadd4973a81ff41626be3274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258658 64665\n"
     ]
    }
   ],
   "source": [
    "train_dl, test_dl = prepare_data(batch_size=128)\n",
    "print(len(train_dl.dataset), len(test_dl.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7408e6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "paths = [float(x[:-4]) for x in os.listdir('models') if not x.startswith('.')]\n",
    "best = min(paths)\n",
    "\n",
    "model.load_state_dict(torch.load(f'models/{best:.6f}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d632261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (hidden1): Linear(in_features=119, out_features=256, bias=True)\n",
       "  (act1): SELU()\n",
       "  (hidden2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (act2): SELU()\n",
       "  (hidden3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (act3): SELU()\n",
       "  (hidden4): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (act4): SELU()\n",
       "  (hidden5): Linear(in_features=64, out_features=8, bias=True)\n",
       "  (act5): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f420cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c8689a9ef245ab915dca9454b71cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \tTraining Loss: 0.21746713860178868 \t Validation Loss: 0.010990423588413494\n",
      "Validation Loss Decreased(inf--->5.561154) \t Saving The Model\n",
      "Epoch 2 \tTraining Loss: 0.2147982468527181 \t Validation Loss: 0.010320866708698952\n",
      "Validation Loss Decreased(5.561154--->5.222359) \t Saving The Model\n",
      "Epoch 3 \tTraining Loss: 0.2132507605991524 \t Validation Loss: 0.010760503235777376\n",
      "Epoch 4 \tTraining Loss: 0.21213402352464017 \t Validation Loss: 0.010422770331499605\n",
      "Epoch 5 \tTraining Loss: 0.21108748401408736 \t Validation Loss: 0.012355612907485058\n",
      "Epoch 6 \tTraining Loss: 0.21035372922616333 \t Validation Loss: 0.012735367233574154\n",
      "Epoch 7 \tTraining Loss: 0.2095684059874838 \t Validation Loss: 0.011189185495197537\n",
      "Epoch 8 \tTraining Loss: 0.20874481078629917 \t Validation Loss: 0.011515888300808992\n",
      "Epoch 9 \tTraining Loss: 0.20815816730305087 \t Validation Loss: 0.010849783572519249\n",
      "Epoch 10 \tTraining Loss: 0.20767590534061797 \t Validation Loss: 0.012090942811353405\n",
      "Epoch 11 \tTraining Loss: 0.2071126942172138 \t Validation Loss: 0.01190850665800185\n",
      "Epoch 12 \tTraining Loss: 0.20674118261004604 \t Validation Loss: 0.011091085938596914\n",
      "Epoch 13 \tTraining Loss: 0.2062480287688136 \t Validation Loss: 0.012112284454667992\n",
      "Epoch 14 \tTraining Loss: 0.20572629579808793 \t Validation Loss: 0.01105323595845181\n",
      "Epoch 15 \tTraining Loss: 0.2053579283727979 \t Validation Loss: 0.011136597795448755\n",
      "Epoch 16 \tTraining Loss: 0.2049754625614889 \t Validation Loss: 0.011316142799590416\n",
      "Epoch 17 \tTraining Loss: 0.20458478677809563 \t Validation Loss: 0.011609359957248325\n",
      "Epoch 18 \tTraining Loss: 0.20425630725444632 \t Validation Loss: 0.01118184976544776\n",
      "Epoch 19 \tTraining Loss: 0.2039439368961708 \t Validation Loss: 0.011576959502555636\n",
      "Epoch 20 \tTraining Loss: 0.20361286361196265 \t Validation Loss: 0.012396167036101751\n",
      "Epoch 21 \tTraining Loss: 0.20327244524257362 \t Validation Loss: 0.011576249783218143\n",
      "Epoch 22 \tTraining Loss: 0.20286964549545247 \t Validation Loss: 0.0119174458822714\n",
      "Epoch 23 \tTraining Loss: 0.20262026416671447 \t Validation Loss: 0.011210329830646515\n",
      "Epoch 24 \tTraining Loss: 0.20229147805222658 \t Validation Loss: 0.011731093020542809\n",
      "Epoch 25 \tTraining Loss: 0.20199801089709374 \t Validation Loss: 0.013012119491580917\n",
      "Epoch 26 \tTraining Loss: 0.20172402264899633 \t Validation Loss: 0.011530753387057262\n",
      "Epoch 27 \tTraining Loss: 0.2015077015997926 \t Validation Loss: 0.012495286262082489\n",
      "Epoch 28 \tTraining Loss: 0.20123849370466607 \t Validation Loss: 0.0124604466993347\n",
      "Epoch 29 \tTraining Loss: 0.20085998199500404 \t Validation Loss: 0.012371254709398323\n",
      "Epoch 30 \tTraining Loss: 0.2007848985238809 \t Validation Loss: 0.012895687236616262\n",
      "Epoch 31 \tTraining Loss: 0.2003372918772025 \t Validation Loss: 0.012740940444554264\n",
      "Epoch 32 \tTraining Loss: 0.20022751042920725 \t Validation Loss: 0.011500499759738153\n",
      "Epoch 33 \tTraining Loss: 0.2000484539547042 \t Validation Loss: 0.011460879162366211\n",
      "Epoch 34 \tTraining Loss: 0.1998988807363595 \t Validation Loss: 0.011939444236840183\n",
      "Epoch 35 \tTraining Loss: 0.1996370683737995 \t Validation Loss: 0.011143700878610724\n",
      "Epoch 36 \tTraining Loss: 0.19942248753838349 \t Validation Loss: 0.013312081927838533\n",
      "Epoch 37 \tTraining Loss: 0.1991714589566892 \t Validation Loss: 0.011614936849345331\n",
      "Epoch 38 \tTraining Loss: 0.19898990076081344 \t Validation Loss: 0.011863203152366306\n",
      "Epoch 39 \tTraining Loss: 0.19867412442915633 \t Validation Loss: 0.012610882167288437\n",
      "Epoch 40 \tTraining Loss: 0.1986539983206725 \t Validation Loss: 0.011864092510208311\n",
      "Epoch 41 \tTraining Loss: 0.1982114508357277 \t Validation Loss: 0.012591236782639395\n",
      "Epoch 42 \tTraining Loss: 0.1982723856284912 \t Validation Loss: 0.01286335819559135\n",
      "Epoch 43 \tTraining Loss: 0.19795246296947042 \t Validation Loss: 0.01265598910128175\n",
      "Epoch 44 \tTraining Loss: 0.19783028653504411 \t Validation Loss: 0.01152684035979712\n",
      "Epoch 45 \tTraining Loss: 0.19768345701051548 \t Validation Loss: 0.0115282318219837\n",
      "Epoch 46 \tTraining Loss: 0.19748487827478217 \t Validation Loss: 0.012381215811718123\n",
      "Epoch 47 \tTraining Loss: 0.1974075905377767 \t Validation Loss: 0.011085397876769657\n",
      "Epoch 48 \tTraining Loss: 0.1970458211343162 \t Validation Loss: 0.012137708456619926\n",
      "Epoch 49 \tTraining Loss: 0.19705763959843353 \t Validation Loss: 0.01232341712289177\n",
      "Epoch 50 \tTraining Loss: 0.19676534947282545 \t Validation Loss: 0.01193826259831666\n",
      "Epoch 51 \tTraining Loss: 0.1966721547499321 \t Validation Loss: 0.011996841683924906\n",
      "Epoch 52 \tTraining Loss: 0.19645800145471054 \t Validation Loss: 0.012442047004643166\n",
      "Epoch 53 \tTraining Loss: 0.19632998490793643 \t Validation Loss: 0.012214462688789066\n",
      "Epoch 54 \tTraining Loss: 0.1961555879771385 \t Validation Loss: 0.012754249890802406\n",
      "Epoch 55 \tTraining Loss: 0.19611230960050355 \t Validation Loss: 0.012586312920679688\n",
      "Epoch 56 \tTraining Loss: 0.19598124918372603 \t Validation Loss: 0.012253022388271664\n",
      "Epoch 57 \tTraining Loss: 0.1957638889978806 \t Validation Loss: 0.011372271733792873\n",
      "Epoch 58 \tTraining Loss: 0.19574584030002015 \t Validation Loss: 0.012837340061372448\n",
      "Epoch 59 \tTraining Loss: 0.19556068947915686 \t Validation Loss: 0.01170158518750677\n",
      "Epoch 60 \tTraining Loss: 0.19533423363484115 \t Validation Loss: 0.013105450529354834\n",
      "Epoch 61 \tTraining Loss: 0.19528173072423044 \t Validation Loss: 0.012104951669811731\n",
      "Epoch 62 \tTraining Loss: 0.1951557182619797 \t Validation Loss: 0.011947310047422945\n",
      "Epoch 63 \tTraining Loss: 0.19509027172055118 \t Validation Loss: 0.01298487039187209\n",
      "Epoch 64 \tTraining Loss: 0.19481095573590687 \t Validation Loss: 0.012678143535206911\n",
      "Epoch 65 \tTraining Loss: 0.19497926850268182 \t Validation Loss: 0.01201728366227018\n",
      "Epoch 66 \tTraining Loss: 0.1945639815234949 \t Validation Loss: 0.01251593732786744\n",
      "Epoch 67 \tTraining Loss: 0.19466148650127138 \t Validation Loss: 0.012440696770965817\n",
      "Epoch 68 \tTraining Loss: 0.19443499840674336 \t Validation Loss: 0.012552875127245787\n",
      "Epoch 69 \tTraining Loss: 0.19433228439296135 \t Validation Loss: 0.01276555680945928\n",
      "Epoch 70 \tTraining Loss: 0.1943056622777228 \t Validation Loss: 0.01336201259741199\n",
      "Epoch 71 \tTraining Loss: 0.19408989480555147 \t Validation Loss: 0.013707647387218098\n",
      "Epoch 72 \tTraining Loss: 0.1939442403492864 \t Validation Loss: 0.012164079978060816\n",
      "Epoch 73 \tTraining Loss: 0.19384910923487358 \t Validation Loss: 0.012435406269763298\n",
      "Epoch 74 \tTraining Loss: 0.1937212210327372 \t Validation Loss: 0.012597360688707104\n",
      "Epoch 75 \tTraining Loss: 0.1936645201015213 \t Validation Loss: 0.013382675442771007\n",
      "Epoch 76 \tTraining Loss: 0.1936617797403746 \t Validation Loss: 0.012673589257383535\n",
      "Epoch 77 \tTraining Loss: 0.19344364053568353 \t Validation Loss: 0.01340482104201562\n",
      "Epoch 78 \tTraining Loss: 0.19340108652064142 \t Validation Loss: 0.012363503749662708\n",
      "Epoch 79 \tTraining Loss: 0.19332278271761935 \t Validation Loss: 0.0132831881051007\n",
      "Epoch 80 \tTraining Loss: 0.19322108733571441 \t Validation Loss: 0.01369088210842826\n",
      "Epoch 81 \tTraining Loss: 0.1930718838372247 \t Validation Loss: 0.013545385226901812\n",
      "Epoch 82 \tTraining Loss: 0.1928408911091334 \t Validation Loss: 0.012893977725929893\n",
      "Epoch 83 \tTraining Loss: 0.19297539466003094 \t Validation Loss: 0.012355160866330263\n",
      "Epoch 84 \tTraining Loss: 0.19282737686190493 \t Validation Loss: 0.013092011507791964\n",
      "Epoch 85 \tTraining Loss: 0.1926351533350173 \t Validation Loss: 0.014068147999495857\n",
      "Epoch 86 \tTraining Loss: 0.1926753179072036 \t Validation Loss: 0.012732205890384117\n",
      "Epoch 87 \tTraining Loss: 0.19249639945092736 \t Validation Loss: 0.012431476309365435\n",
      "Epoch 88 \tTraining Loss: 0.19219692258596538 \t Validation Loss: 0.013635737504883717\n",
      "Epoch 89 \tTraining Loss: 0.19243767749166088 \t Validation Loss: 0.012076222761110826\n",
      "Epoch 90 \tTraining Loss: 0.19217038908139247 \t Validation Loss: 0.012327271252281582\n",
      "Epoch 91 \tTraining Loss: 0.1921759244461923 \t Validation Loss: 0.014136635915563982\n",
      "Epoch 92 \tTraining Loss: 0.19210290507713443 \t Validation Loss: 0.012916952312699419\n",
      "Epoch 93 \tTraining Loss: 0.19189219131792967 \t Validation Loss: 0.012330785982693607\n",
      "Epoch 94 \tTraining Loss: 0.19186177035772464 \t Validation Loss: 0.012097535691713627\n",
      "Epoch 95 \tTraining Loss: 0.19189592836842215 \t Validation Loss: 0.011347564813412226\n",
      "Epoch 96 \tTraining Loss: 0.19166885813323062 \t Validation Loss: 0.0136373159678086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 \tTraining Loss: 0.19167832935110052 \t Validation Loss: 0.012708246236733297\n",
      "Epoch 98 \tTraining Loss: 0.19164787298496969 \t Validation Loss: 0.014355406165122986\n",
      "Epoch 99 \tTraining Loss: 0.19143307685321184 \t Validation Loss: 0.013229090411201296\n",
      "Epoch 100 \tTraining Loss: 0.19149995966455477 \t Validation Loss: 0.013216069564517778\n",
      "Epoch 101 \tTraining Loss: 0.1912779656968336 \t Validation Loss: 0.012732978924932217\n",
      "Epoch 102 \tTraining Loss: 0.19127210435715128 \t Validation Loss: 0.012425925185086699\n",
      "Epoch 103 \tTraining Loss: 0.19117935178806025 \t Validation Loss: 0.013622875682450094\n",
      "Epoch 104 \tTraining Loss: 0.19098058637122833 \t Validation Loss: 0.013623606016042204\n",
      "Epoch 105 \tTraining Loss: 0.19107239544096705 \t Validation Loss: 0.013203134119746242\n",
      "Epoch 106 \tTraining Loss: 0.19095091123589192 \t Validation Loss: 0.01196420416530413\n",
      "Epoch 107 \tTraining Loss: 0.19085100301269964 \t Validation Loss: 0.012595710075891066\n",
      "Epoch 108 \tTraining Loss: 0.19073817883016803 \t Validation Loss: 0.012782316198462084\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train_model(train_dl, test_dl, model, epochs = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d6deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "acc = evaluate_model(test_dl, model)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "# make a single prediction (expect class=1)\n",
    "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
    "yhat = predict(row, model)\n",
    "print('Predicted: %.3f (class=%d)' % (yhat, yhat.round()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
